{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade156dc-9473-401a-9018-e35641f0325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import libraries\n",
    "import earthaccess \n",
    "import geopandas as gdp\n",
    "import os\n",
    "from pathlib import Path\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57304e0c-2590-4ddd-b6a4-5c5bef321811",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Provide login credentials, cant be set up on urs.earthdata.nasa.gov\n",
    "earthaccess.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde8c599-9722-4604-b159-28c6a4e88f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This notebook is set up to download data per tile / shapefile. \n",
    "# Provide a shapefile here\n",
    "shapefile = \"path/file.shp\"\n",
    "\n",
    "# Important! The shapefile example here assumes there is an ID for each polygon/tile called \"Name\"\n",
    "# This ID is used in the #query and download section below. Swap ID as needed. \n",
    "\n",
    "gdf = gdp.read_file(shapefile)\n",
    "gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "print(gdf.crs)\n",
    "\n",
    "unique_shapes = gdf.geometry.nunique()\n",
    "print(f\"Number of unique shapes: {unique_shapes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3d8f2b-8c15-4fe8-8174-399aed670c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many tiles/shapefiles are we dealing with?\n",
    "gdf_unique = (\n",
    "    gdf.drop_duplicates(subset=\"geometry\")\n",
    "       .copy()\n",
    "       .reset_index(drop=True)\n",
    ")\n",
    "# quick fix for minor geometry issues (optional)\n",
    "gdf_unique[\"geometry\"] = gdf_unique.geometry.buffer(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d1a1c-5863-40a4-a084-7d46bede95de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output folder, data collection name, etc. \n",
    "BASE_OUT   = Path(\"path/folder\")\n",
    "\n",
    "#collection short name\n",
    "SHORT_NAME = \"HLSS30\"\n",
    "\n",
    "#set time range\n",
    "TEMPORAL   = (\"2017-01-01T00:00:00\", \"2020-12-30T23:59:00\")\n",
    "\n",
    "#tolerable cloud cover i.e. <50%\n",
    "CLOUD_COV  = (0, 50)\n",
    "\n",
    "# Required band keywords to keep (removes all others)\n",
    "KEEP_KEYWORDS = (\"B02\", \"B04\", \"B8A\", \"Fmask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794669bc-8ccd-4501-b9c8-c8c516a2fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query and download\n",
    "for i, row in gdf_unique.iterrows():\n",
    "    name = str(row[\"Name\"]).replace(\" \", \"_\").replace(\"/\", \"-\")  # folder name\n",
    "    outdir = BASE_OUT / name\n",
    "\n",
    "    # --- Skip if folder already exists ---\n",
    "    if outdir.exists() and any(outdir.iterdir()):\n",
    "        print(f\"[{i+1}/{len(gdf_unique)}] {name}: already exists, skipping.\")\n",
    "        continue\n",
    "   \n",
    "    minx, miny, maxx, maxy = row.geometry.bounds\n",
    "    bbox = (minx, miny, maxx, maxy)\n",
    "\n",
    "    try:\n",
    "        results = earthaccess.search_data(\n",
    "            short_name=SHORT_NAME,\n",
    "            bounding_box=bbox,\n",
    "            temporal=TEMPORAL,\n",
    "            cloud_cover=CLOUD_COV\n",
    "        )\n",
    "\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "        print(f\"[{i+1}/{len(gdf_unique)}] {name}: bbox={bbox}, hits={len(results)}\")\n",
    "        if results:\n",
    "            earthaccess.download(results, str(outdir))\n",
    "\n",
    "        # --- Clean downloaded files ---\n",
    "        #If you want to keep all bands, remove code below - keep the sleep (0.5) piece onwards.\n",
    "        for f in Path(outdir).iterdir():\n",
    "            # Delete if none of the keywords appear in filename\n",
    "            if not any(k in f.name for k in KEEP_KEYWORDS):\n",
    "                f.unlink()\n",
    "        print(f\"  â†’ Cleaned: kept only {KEEP_KEYWORDS}\")\n",
    "        sleep(0.5)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on {name}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
